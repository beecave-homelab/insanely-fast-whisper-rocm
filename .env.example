# Insanely Fast Whisper API - Environment Configuration
# This file contains the runtime configuration for the Insanely Fast Whisper API

#------------------------------------------------------------------------------
# Model Configuration
#------------------------------------------------------------------------------

# The Whisper model to use for transcription/translation
# Options: openai/whisper-tiny, openai/whisper-base, openai/whisper-small,
#          openai/whisper-medium, openai/whisper-large-v3, 
#          distil-whisper/distil-large-v2, distil-whisper/distil-large-v3
WHISPER_MODEL=distil-whisper/distil-large-v3

# Device ID for GPU
# Options: "0", "1", etc. for CUDA GPUs, "mps" for Apple Silicon, "cpu" for CPU
WHISPER_DEVICE=0

# Batch size for processing audio chunks
# Higher values = faster processing but more memory usage
# Range: 1-32 (default: 4)
WHISPER_BATCH_SIZE=4

# Type of timestamps to generate
# Options: chunk, word
WHISPER_TIMESTAMP_TYPE=chunk

# Language for transcription/translation
# Set to None for auto-detection
# Or use ISO language code: en, fr, de, es, etc.
WHISPER_LANGUAGE=None

# Data type for model inference
# Options: float16, float32, bfloat16
# Default: float16 (recommended for better performance)
WHISPER_DTYPE=float16

# Enable BetterTransformer optimization
# Options: true, false (default: false)
WHISPER_BETTER_TRANSFORMER=false

# Audio chunk length in seconds for processing
# Default: 30 seconds
WHISPER_CHUNK_LENGTH=30

#------------------------------------------------------------------------------
# Diarization Configuration
#------------------------------------------------------------------------------

# Model to use for speaker diarization
WHISPER_DIARIZATION_MODEL=pyannote/speaker-diarization

# HuggingFace token for accessing diarization models
# Get your token at: https://hf.co/settings/tokens
# HF_TOKEN=your_huggingface_token_here

#------------------------------------------------------------------------------
# File Handling
#------------------------------------------------------------------------------

# Directory for temporary file uploads
# Default: temp_uploads
WHISPER_UPLOAD_DIR=temp_uploads

# Directory for saved transcription files
WHISPER_TRANSCRIPTS_DIR=transcripts

# Timezone for filename timestamps
# Options: UTC (default), or any valid timezone name (e.g., Europe/Amsterdam, America/New_York)
# Affects the timestamp format in generated filenames: {audio_stem}_{task}_{timestamp}.{extension}
FILENAME_TIMEZONE=Europe/Amsterdam

#------------------------------------------------------------------------------
# Audio Chunking Configuration
#------------------------------------------------------------------------------

# Maximum duration of each audio chunk in seconds
# Default: 600 (10 minutes)
AUDIO_CHUNK_DURATION=600

# Overlap duration between chunks in seconds
# Helps prevent cutting off words at chunk boundaries
# Default: 1.0
AUDIO_CHUNK_OVERLAP=1.0

# Minimum duration of a chunk in seconds
# Files shorter than this won't be chunked
# Default: 5.0
AUDIO_CHUNK_MIN_DURATION=5.0

#------------------------------------------------------------------------------
# ROCm/HIP Configuration (for AMD GPUs)
#------------------------------------------------------------------------------

# PyTorch ROCm/HIP memory allocation configuration
# PYTORCH_HIP_ALLOC_CONF=expandable_segments:True

# Override for rocm support for RX6600
HSA_OVERRIDE_GFX_VERSION=10.3.0

# For synchronous HIP kernel launches and better error reporting (uncomment if needed)
# HIP_LAUNCH_BLOCKING=1

#------------------------------------------------------------------------------
# Additional Configuration Options
#------------------------------------------------------------------------------

# Hugging Face API token for accessing private/gated models
# HUGGINGFACE_TOKEN=your_huggingface_token_here

# Whether to save transcription results to disk
# Options: true, false
SAVE_TRANSCRIPTIONS=true

# API server configuration
API_HOST=0.0.0.0
API_PORT=8888

# Logging level
# Options: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

#------------------------------------------------------------------------------
# Usage Notes:
#------------------------------------------------------------------------------
# 1. All values are case-sensitive
# 2. Boolean values should be 'true' or 'false' (lowercase)
# 3. Numeric values should be integers unless otherwise specified
# 4. Language codes should follow ISO standards (e.g., 'en', 'fr', 'de')
# 5. Model names must match the Hugging Face model hub names
# 6. Filename timestamps use format: {audio_stem}_{task}_{timestamp}.{extension}
#    Example: my_audio_transcribe_20250530T143022Z.json
#
# For more information about supported languages, visit:
# https://github.com/openai/whisper/blob/main/whisper/tokenizer.py#L10